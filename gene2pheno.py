# -*- coding: utf-8 -*-
"""Gene2Pheno.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w0bL4bvX5clT7c3AxcluSHnwpt9jcZZE
"""

from google.colab import drive
drive.mount('/content/drive')

from google.oauth2.service_account import Credentials

import pandas as pd
import numpy as np

###############################################################################
# 1) Read CSV
###############################################################################
df = pd.read_csv("G2P_Eye_2025-03-01.csv")  # Update filename/path if needed

###############################################################################
# 2) Define Mappings for Key Columns
###############################################################################

# (A) Molecular Mechanism → one-hot for LoF, GoF, DN
# Updated to match the "molecular mechanism" column values you showed:
#   - "loss of function"
#   - "dominant negative"
#   - "undetermined"
#   - (Optionally) "gain of function"
mechanism_map = {
    "loss of function":      (1, 0, 0),
    "gain of function":      (0, 1, 0),
    "dominant negative":     (0, 0, 1),
    "undetermined":          (0, 0, 0)   # or however you wish to handle "undetermined"
}

# (B) GenCC Confidence → numeric scale (optional if your CSV has a "confidence" column)
# Example mapping: definitive=5, strong=4, moderate=3, limited=2, disputed=1, refuted=0
confidence_map = {
    "definitive": 5,
    "strong":     4,
    "moderate":   3,
    "limited":    2,
    "disputed":   1,
    "refuted":    0
}

# (C) Allelic Requirement Mapping (optional)
allelic_requirement_map = {
    "biallelic_autosomal":    "AR",
    "biallelic_PAR":          "AR",
    "monoallelic_autosomal":  "AD",
    "monoallelic_PAR":        "AD",
    "monoallelic_X":          "X-linked",
    "monoallelic_X_hemizygous":     "X-linked (hemizygous)",
    "monoallelic_X_heterozygous":   "X-linked (heterozygous)",
    "monoallelic_Y_hemizygous":     "Y-linked",
    "mitochondrial":                "mtDNA"
}

###############################################################################
# 3) Helper Functions
###############################################################################

def parse_mechanism_cat(mech_str):
    """
    Return a tuple (LoF, GoF, DN) based on the 'molecular mechanism' column.
    """
    if pd.isna(mech_str):
        return (0, 0, 0)
    # Normalize (lowercase & strip)
    key = mech_str.strip().lower()
    return mechanism_map.get(key, (0, 0, 0))

def parse_confidence(conf_str):
    """
    Convert GenCC confidence terms (definitive, strong, etc.) to a numeric scale.
    """
    if pd.isna(conf_str):
        return 0
    key = conf_str.strip().lower()
    return confidence_map.get(key, 0)

def parse_allelic_requirement(ar_str):
    """
    Simplify 'allelic requirement' to a short code (e.g., AR, AD, etc.).
    """
    if pd.isna(ar_str):
        return ""
    key = ar_str.strip()
    return allelic_requirement_map.get(key, key)

###############################################################################
# 4) Apply Transformations to DataFrame
###############################################################################

# -- PARSE MOLECULAR MECHANISM --
# Use the "molecular mechanism" column (NOT "molecular mechanism categorisation")
df["LoF"], df["GoF"], df["DN"] = zip(*df["molecular mechanism"].apply(parse_mechanism_cat))

# -- PARSE CONFIDENCE (if your CSV has a column named 'confidence') --
df["ConfidenceScore"] = df["confidence"].apply(parse_confidence) if "confidence" in df.columns else 0

# -- BUILD 4D VECTOR <LoF, GoF, DN, Confidence> (only if you have 'confidence' data) --
df["Mechanism_Vector_4D"] = df.apply(
    lambda row: np.array([
        row["LoF"],
        row["GoF"],
        row["DN"],
        row["ConfidenceScore"]
    ]),
    axis=1
)

# -- PARSE ALLELIC REQUIREMENT --
if "allelic requirement" in df.columns:
    df["AllelicReq_Simplified"] = df["allelic requirement"].apply(parse_allelic_requirement)

###############################################################################
# 5) Inspect or Export
###############################################################################

print(df[[
    "gene symbol",
    "disease name",
    "molecular mechanism",
    "LoF", "GoF", "DN",
    "ConfidenceScore",
    "Mechanism_Vector_4D"
]].head(20))

df.to_csv("G2P_annotated.csv", index=False)

import pandas as pd
import numpy as np

###############################################################################
# 1) Define List of Dataset Filenames
###############################################################################
datasets = [
    "G2P_Cancer_2025-03-01.csv",
    "G2P_Cardiac_2025-03-01.csv",
    "G2P_DD_2025-03-01.csv",
    "G2P_Hearing loss_2025-03-01.csv",
    "G2P_Skeletal_2025-03-01.csv",
    "G2P_Skin_2025-03-01.csv",
    "G2P_Eye_2025-03-01.csv"
]

###############################################################################
# 2) Define Mappings for Key Columns
###############################################################################

# (A) Molecular Mechanism → one-hot for LoF, GoF, DN
mechanism_map = {
    "loss of function":      (1, 0, 0),
    "gain of function":      (0, 1, 0),
    "dominant negative":     (0, 0, 1),
    "undetermined":          (0, 0, 0)  # Adjust if needed
}

# (B) GenCC Confidence → numeric scale
confidence_map = {
    "definitive": 5,
    "strong":     4,
    "moderate":   3,
    "limited":    2,
    "disputed":   1,
    "refuted":    0
}

# (C) Allelic Requirement Mapping (optional)
allelic_requirement_map = {
    "biallelic_autosomal":    "AR",
    "biallelic_PAR":          "AR",
    "monoallelic_autosomal":   "AD",
    "monoallelic_PAR":         "AD",
    "monoallelic_X":           "X-linked",
    "monoallelic_X_hemizygous": "X-linked (hemizygous)",
    "monoallelic_X_heterozygous": "X-linked (heterozygous)",
    "monoallelic_Y_hemizygous": "Y-linked",
    "mitochondrial":          "mtDNA"
}

###############################################################################
# 3) Helper Functions
###############################################################################

def parse_mechanism_cat(mech_str):
    """
    Return a tuple (LoF, GoF, DN) based on the 'molecular mechanism' column.
    """
    if pd.isna(mech_str):
        return (0, 0, 0)
    key = mech_str.strip().lower()
    return mechanism_map.get(key, (0, 0, 0))

def parse_confidence(conf_str):
    """
    Convert GenCC confidence terms (definitive, strong, etc.) to a numeric scale.
    """
    if pd.isna(conf_str):
        return 0
    key = conf_str.strip().lower()
    return confidence_map.get(key, 0)

def parse_allelic_requirement(ar_str):
    """
    Simplify 'allelic requirement' to a short code (e.g., AR, AD, etc.).
    """
    if pd.isna(ar_str):
        return ""
    key = ar_str.strip()
    return allelic_requirement_map.get(key, key)

###############################################################################
# 4) Process Each Dataset and Combine Results
###############################################################################

processed_dfs = []

for filename in datasets:
    print(f"Processing file: {filename}")
    # Read the dataset
    df = pd.read_csv(filename)

    # Optionally, add a column to indicate the dataset domain (extracted from filename)
    df["dataset"] = filename

    # -- PARSE MOLECULAR MECHANISM --
    df["LoF"], df["GoF"], df["DN"] = zip(*df["molecular mechanism"].apply(parse_mechanism_cat))

    # -- PARSE CONFIDENCE --
    if "confidence" in df.columns:
        df["ConfidenceScore"] = df["confidence"].apply(parse_confidence)
    else:
        df["ConfidenceScore"] = 0

    # -- BUILD 4D VECTOR <LoF, GoF, DN, ConfidenceScore> --
    df["Mechanism_Vector_4D"] = df.apply(
        lambda row: np.array([
            row["LoF"],
            row["GoF"],
            row["DN"],
            row["ConfidenceScore"]
        ]),
        axis=1
    )

    # -- PARSE ALLELIC REQUIREMENT (if present) --
    if "allelic requirement" in df.columns:
        df["AllelicReq_Simplified"] = df["allelic requirement"].apply(parse_allelic_requirement)

    # Append the processed DataFrame to our list
    processed_dfs.append(df)

# Combine all processed DataFrames into one
df_combined = pd.concat(processed_dfs, ignore_index=True)

###############################################################################
# 5) Inspect or Export the Combined Data
###############################################################################

print(df_combined[[
    "dataset",
    "gene symbol",
    "disease name",
    "molecular mechanism",
    "LoF", "GoF", "DN",
    "ConfidenceScore",
    "Mechanism_Vector_4D"
]].head(20))

# Save the combined DataFrame to a CSV file
df_combined.to_csv("G2P_all_annotated.csv", index=False)

print("✅ Processed data saved as 'G2P_all_annotated.csv'")

import pandas as pd
import numpy as np

###############################################################################
# 1) Define List of Dataset Filenames
###############################################################################
datasets = [
    "G2P_Cancer_2025-03-01.csv",
    "G2P_Cardiac_2025-03-01.csv",
    "G2P_DD_2025-03-01.csv",
    "G2P_Hearing loss_2025-03-01.csv",
    "G2P_Skeletal_2025-03-01.csv",
    "G2P_Skin_2025-03-01.csv",
    "G2P_Eye_2025-03-01.csv"
]

###############################################################################
# 2) Define Mappings for Key Columns
###############################################################################

mechanism_map = {
    "loss of function": (1, 0, 0),
    "gain of function": (0, 1, 0),
    "dominant negative": (0, 0, 1),
    "undetermined": (0, 0, 0)
}

confidence_map = {
    "definitive": 5,
    "strong": 4,
    "moderate": 3,
    "limited": 2,
    "disputed": 1,
    "refuted": 0
}

allelic_requirement_map = {
    "biallelic_autosomal": "AR",
    "biallelic_PAR": "AR",
    "monoallelic_autosomal": "AD",
    "monoallelic_PAR": "AD",
    "monoallelic_X": "X-linked",
    "monoallelic_X_hemizygous": "X-linked (hemizygous)",
    "monoallelic_X_heterozygous": "X-linked (heterozygous)",
    "monoallelic_Y_hemizygous": "Y-linked",
    "mitochondrial": "mtDNA"
}

###############################################################################
# 3) Helper Functions
###############################################################################

def parse_mechanism_cat(mech_str):
    """ Convert 'molecular mechanism' column into (LoF, GoF, DN) tuple. """
    if pd.isna(mech_str):
        return (0, 0, 0)
    return mechanism_map.get(mech_str.strip().lower(), (0, 0, 0))

def parse_confidence(conf_str):
    """ Convert GenCC confidence terms to numeric scale. """
    if pd.isna(conf_str):
        return 0
    return confidence_map.get(conf_str.strip().lower(), 0)

def parse_allelic_requirement(ar_str):
    """ Convert allelic requirement into short codes like 'AD', 'AR', etc. """
    if pd.isna(ar_str):
        return ""
    return allelic_requirement_map.get(ar_str.strip(), ar_str)

def log_normalize(series):
    """ Apply log normalization: log(1 + x) / log(1 + max(x)) to a Pandas Series. """
    if series.max() == 0:
        return series  # Avoid division by zero if all values are zero
    return np.log1p(series) / np.log1p(series.max())

###############################################################################
# 4) Process Each Dataset and Combine Results
###############################################################################

processed_dfs = []

for filename in datasets:
    print(f"Processing file: {filename}")

    try:
        df = pd.read_csv(filename)
        df["dataset"] = filename

        # Parse Molecular Mechanism
        if "molecular mechanism" in df.columns:
            df["LoF"], df["GoF"], df["DN"] = zip(*df["molecular mechanism"].apply(parse_mechanism_cat))

        # Parse Confidence Levels
        df["ConfidenceScore"] = df["confidence"].apply(parse_confidence) if "confidence" in df.columns else 0

        # Append to list for global normalization later
        processed_dfs.append(df)

    except FileNotFoundError:
        print(f"⚠️ Warning: File {filename} not found. Skipping.")
    except Exception as e:
        print(f"⚠️ Error processing {filename}: {e}")

###############################################################################
# 5) Normalize Confidence Score
###############################################################################

if processed_dfs:
    df_combined = pd.concat(processed_dfs, ignore_index=True)

    # Log Normalization of ConfidenceScore
    df_combined["ConfidenceScore"] = log_normalize(df_combined["ConfidenceScore"])

    # Build 4D Mechanism Vector in proper list format
    df_combined["Mechanism_Vector_4D"] = df_combined.apply(lambda row:
        f"[{row['LoF']}, {row['GoF']}, {row['DN']}, {row['ConfidenceScore']:.4f}]", axis=1)

    print("Sample of processed data:")
    columns_to_display = [col for col in [
        "dataset", "gene symbol", "disease name", "molecular mechanism",
        "LoF", "GoF", "DN", "ConfidenceScore", "Mechanism_Vector_4D"
    ] if col in df_combined.columns]

    print(df_combined[columns_to_display].head(5))

    # Save the processed data
    df_combined.to_csv("G2P_all_annotated.csv", index=False)

    print("✅ Data saved to G2P_all_annotated.csv")
else:
    print("❌ No data was processed. Check file paths and try again.")